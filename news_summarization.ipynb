{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vasil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vasil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "from string import punctuation\n",
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Idea for Step 1 ###\n",
    "If a sentence contains the most keywords, it is the most important sentence. Rank the sentences by the number of keywords they contain. Then select the first n sentences as the summary.\n",
    "\n",
    "Calculate the frequency score for every word in the article\n",
    "Calculate the frequency score for every sentence\n",
    "Rank sentences by frequency score\n",
    "Get the first n sentences as summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(stopwords.words('english') + list(punctuation)) # filter out stopwords and puncts\n",
    "max_cut = 0.9 # filter out the word with highest frequency\n",
    "min_cut = 0.1 # filter out the word with lowest frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculate the frequency for each word\n",
    "word_sent: list of words\n",
    "return freq dict\n",
    "freq[w]: the frequency of w\n",
    "\"\"\"\n",
    "def compute_frequencies(word_sent):\n",
    "    \"\"\"\n",
    "    defaultdict is a dict with default value\n",
    "    for int the default value is 0\n",
    "    \"\"\"\n",
    "    freq = defaultdict(int)\n",
    "\n",
    "    #count the appearances for each word\n",
    "    for s in word_sent:\n",
    "        for word in s:\n",
    "            # exlude stopwords\n",
    "            if word not in stopwords:\n",
    "                freq[word] += 1\n",
    "\n",
    "    # get the highest frequency m\n",
    "    m = float(max(freq.values()))\n",
    "    \n",
    "    #all frequency / m\n",
    "    for w in list(freq.keys()):\n",
    "        freq[w] = freq[w]/m\n",
    "        if freq[w] >= max_cut or freq[w] <= min_cut:\n",
    "            del freq[w]\n",
    "    # Return\n",
    "    # {key:word, value: weight score}\n",
    "    return freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Summary ###\n",
    "Adding up the frequency score in each word for every sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(text, n):\n",
    "    \"\"\"\n",
    "    function for summarize\n",
    "    text: input news file\n",
    "    n: number of sentences in summary\n",
    "    return the list of sentences in the summary\n",
    "    \"\"\"\n",
    "\n",
    "    # tokenize sentences\n",
    "    sents = sent_tokenize(text)\n",
    "    assert n <= len(sents)\n",
    "\n",
    "    # tokenize words\n",
    "    word_sent = [word_tokenize(s.lower()) for s in sents]\n",
    "\n",
    "    # freq: dictionary for words and its frequency score\n",
    "    freq = compute_frequencies(word_sent)\n",
    "    \n",
    "    #ranking: dictionary for sentences and its frequency score\n",
    "    ranking = defaultdict(int)\n",
    "    for i, word in enumerate(word_sent):\n",
    "        for w in word:\n",
    "            if w in freq:\n",
    "                ranking[i] += freq[w]\n",
    "    sents_idx = rank(ranking, n)\n",
    "    return [sents[j] for j in sents_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Iteration will be very slow for long articles.\n",
    "Use function in heapq\n",
    "创建一个最小堆来完成这个功能\n",
    "返回的是最小的n个数所在的位置\n",
    "\"\"\"    \n",
    "def rank(ranking, n):\n",
    "    return nlargest(n, ranking, key=ranking.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Modern life is dramatically different to even 30 years ago,\" Prof Gray told Radio 4's Today programme, \"people now drive to work and sit at work.\"\n",
      "\"The How Are You Quiz will help anyone who wants to take a few minutes to take stock and find out quickly where they can take a little action to make a big difference to their health.\"\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    with open(\"news.txt\", \"r\") as myfile:\n",
    "        text = myfile.read().replace('\\n','')\n",
    "    res = summarize(text, 2)\n",
    "    for i in range(len(res)):\n",
    "        print(res[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/news-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/news-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/news-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/news-4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原文： [**'Middle age Health Crisis' Warning**](http://www.bbc.com/news/health-38402655)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem ###\n",
    "Simply adding up frequency score will prioritize long sentences. In the next step we need to improve the algorithm for summary."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
